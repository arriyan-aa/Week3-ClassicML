{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywb8NifF9XN3",
        "outputId": "02574e3b-b411-4a94-d624-1abe3bcb3e45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5CvOjjrL9gw"
      },
      "source": [
        "<center><h1> Introduction to Audio Classification with Machine Learning Models </h1></center>\n",
        "\n",
        "\n",
        "\n",
        "### Purpose\n",
        "This notebook serves as an introduction to working with audio data for classification problems; it is meant as a learning resource rather than a demonstration of the state-of-the-art. The techniques mentioned in this notebook apply not only to classification problems, but to regression problems and problems dealing with other types of input data as well. I provide an introduction to a few key machine learning models and the logic in choosing their hyperparameters. These objectives are framed by the task of recognizing emotion from snippets of speech audio.\n",
        "\n",
        " Training data should be used strictly for training a model, validation data strictly for tuning a model, and test data strictly to evaluate a model once it is tuned - a model should never be tuned to perform better on test data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Classic machine learning models such as Support Vector Machines (SVM), k Nearest Neighbours (kNN), and Random Forests have distinct advantages to deep neural networks in many tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQsTfGREL9g1"
      },
      "source": [
        "<!--TABLE OF CONTENTS-->\n",
        "\n",
        "\n",
        "# Table of Contents\n",
        "  - [Intro: Speech Emotion Recognition on the RAVDESS dataset](#Intro:-Speech-Emotion-Recognition-on-the-RAVDESS-dataset)\n",
        "  - [Machine Learning Process Overview](#Machine-Learning-Process-Overview)\n",
        "  - [Feature Extraction](#Feature-Extraction)\n",
        "    - [Load the Dataset and Compute Features](#Load-the-Dataset-and-Compute-Features)\n",
        "    - [Feature Scaling](#Feature-Scaling)\n",
        "  - [Classical Machine Learning Models](#Classical-Machine-Learning-Models)\n",
        "    - [Training: The 80/20 Split and Validation](#Training:-The-80/20-Split-and-Validation)\n",
        "    - [Comparing Models](#Comparing-Models)\n",
        "    - [The Support Vector Machine Classifier](#The-Support-Vector-Machine-Classifier)\n",
        "    - [k Nearest Neighbours](#k-Nearest-Neighbours)\n",
        "    - [Random Forests](#Random-Forests)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hZUcbr4PL9g2"
      },
      "source": [
        "## Intro: Speech Emotion Recognition on the RAVDESS dataset\n",
        "In this notebook we explore the most common machine learning models, specifically those available off the shelf in scikit-learn.\n",
        "\n",
        "I'm going to use the RAVDESS dataset (Ryerson Audio-Visual Database of Emotional Speech and Song dataset), created by Steven Livingstone and Frank Russo of Ryerson University. <br>\n",
        "[Details of the RAVDESS dataset](https://smartlaboratory.org/ravdess/) <br>\n",
        "[Download the dataset used in this notebook](https://zenodo.org/record/1188976) <br> Scroll half-way down the page and find \"Audio_Speech_Actors_01-24\"<br>\n",
        "\n",
        "We're going to use the audio-only speech portion of the RAVDESS dataset, ~200MB.\n",
        "Audio is sourced from 24 actors (12 male, 12 female) repeating two sentences with\n",
        "a variety of emotions and intensity. We get 1440 speech files (24 actors * 60 recordings per actor). Each audio sample has been rated  by a human 10 times for emotional quality.\n",
        "\n",
        "## Machine Learning Process Overview\n",
        "1. Feature Engineering: Choose and define the properties which our model will use to evaluate the audio files. <br>\n",
        "2. Feature Extraction: Compute the features for each audio file and build a feature matrix representing all audio files. <br>\n",
        "3. Model exploration: Test candidate models that make sense for the properies of the dataset\n",
        "4. Training the MLP Classifier model: Choose and optimize the properties of our model on validation data - hyperparameters and architechture.  <br>\n",
        "5. Evaluate our model's performance: Evaluate our model's accuracy on validation data and score it against test data which it has never seen in training.<br>\n",
        "6. Explore options for improving our model: Is our dataset the right size? Is our model too complex or too simple? <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install pandas\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install nltk\n",
        "!pip install librosa"
      ],
      "metadata": {
        "id": "YyErrQztlbL-",
        "outputId": "9b04be39-8a10-41b3-fe90-b90af14d69a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (2.3.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.2.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: matplotlib in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (3.10.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: seaborn in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (2.2.6)\n",
            "Requirement already satisfied: pandas>=1.2 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (2.3.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from seaborn) (3.10.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (2.2.6)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: opencv-python in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from opencv-python) (2.2.6)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: nltk in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
            "Requirement already satisfied: click in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (8.3.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2025.9.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: librosa in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (0.11.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (0.62.0)\n",
            "Requirement already satisfied: numpy>=1.22.3 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.7.2)\n",
            "Requirement already satisfied: joblib>=1.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (5.2.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.0.0)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: packaging in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
            "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from numba>=0.51.0->librosa) (0.45.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa) (4.4.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from pooch>=1.1->librosa) (2.32.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from soundfile>=0.12.1->librosa) (2.0.0)\n",
            "Requirement already satisfied: pycparser in c:\\users\\arriy\\appdata\\roaming\\python\\python312\\site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa.display\n",
        "import soundfile\n",
        "import os\n",
        "# matplotlib complains about the behaviour of librosa.display, so we'll ignore those warnings:\n",
        "import warnings; warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "b2IL0uT19_3A"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eu8VPhDmL9hC"
      },
      "source": [
        "## Feature Extraction\n",
        "We're going to take full advantage of librosa, a Python library enabling audio analysis and feature extraction.\n",
        "Librosa abstracts away all the math and most of the details of mel spectrorgams, chromagrams, and MFCC.\n",
        "Although closely related, we're going to take the Mel Spectrogram, MFCC, and chromagrams of each audio file as separate features to try\n",
        "and have bit more discriminatory power between samples. <br>\n",
        "\n",
        "Let's build our feature extraction functions to get a chromagram, a mel spectorgram, and MFC coefficients for each of our audio files. Because the chromagram, mel spectrogram and MFCCs are calculated on audio frames produced by STFT, we're going to get a matrix back from each function, so we'll take the mean of those matrices to produce a single feature array for each feature and each audio sample, i.e. 3 feature arrays per audio sample.\n",
        "\n",
        "**Chromagram**: Will produce 12 features; One for each of 12 pitch classes\n",
        "\n",
        "**Mel Spectrogram**: Will produce 128 features; We've defined the number of mel frequency bands at n_mels=128\n",
        "\n",
        "**MFCC**: Will produce 40 MFCCs; I've set the number of coefficients to return at n_mfcc=40 which I found to work well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qTe93WYTL9hD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def feature_chromagram(waveform, sample_rate):\n",
        "    # STFT computed here explicitly; mel spectrogram and MFCC functions do this under the hood\n",
        "    stft_spectrogram=np.abs(librosa.stft(waveform))\n",
        "    # Produce the chromagram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    chromagram=np.mean(librosa.feature.chroma_stft(S=stft_spectrogram, sr=sample_rate).T,axis=0)\n",
        "    return chromagram\n",
        "\n",
        "def feature_melspectrogram(waveform, sample_rate):\n",
        "    # Produce the mel spectrogram for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    # Using 8khz as upper frequency bound should be enough for most speech classification tasks\n",
        "    melspectrogram=np.mean(librosa.feature.melspectrogram(y=waveform, sr=sample_rate, n_mels=128, fmax=8000).T,axis=0)\n",
        "    return melspectrogram\n",
        "\n",
        "def feature_mfcc(waveform, sample_rate):\n",
        "    # Compute the MFCCs for all STFT frames and get the mean of each column of the resulting matrix to create a feature array\n",
        "    # 40 filterbanks = 40 coefficients\n",
        "    mfc_coefficients=np.mean(librosa.feature.mfcc(y=waveform, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "    return mfc_coefficients"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xjFXIfC2L9hD"
      },
      "source": [
        "We're going to wrap our feature extraction functions so we only have to load each audio file once. After extracting our 3 audio features as NumPy arrays representing a time series, we're going to\n",
        "stack them horizontally to create a single feature array."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_waveform(waveform):\n",
        "    # If the waveform has 2 channels (stereo), convert it to mono\n",
        "    if len(waveform.shape) > 1:\n",
        "        waveform = librosa.to_mono(waveform)\n",
        "    return waveform"
      ],
      "metadata": {
        "id": "f-UK-s6Rhl1F"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "xPMw9ijJL9hE"
      },
      "outputs": [],
      "source": [
        "def get_features(file):\n",
        "    # load an individual soundfile\n",
        "     with soundfile.SoundFile(file) as audio:\n",
        "        waveform = audio.read(dtype=\"float32\")\n",
        "        sample_rate = audio.samplerate\n",
        "        # make sure the file is mono channel audio\n",
        "        waveform = preprocess_waveform(waveform)\n",
        "        # compute features of soundfile\n",
        "        chromagram = feature_chromagram(waveform, sample_rate)\n",
        "        melspectrogram = feature_melspectrogram(waveform, sample_rate)\n",
        "        mfc_coefficients = feature_mfcc(waveform, sample_rate)\n",
        "\n",
        "        feature_matrix=np.array([])\n",
        "\n",
        "        # Check the shape of chromagram\n",
        "        if chromagram.ndim > 1 and chromagram.shape[1] > 1:\n",
        "            #print(f\"Returning zero vector for chromagram size: {file} (shape: {chromagram.shape})\")\n",
        "            chromagram = np.zeros((12,))  # Return a zero vector of size (12,)\n",
        "\n",
        "        # Check the shape of mel spectrogram\n",
        "        if melspectrogram.ndim > 1 and melspectrogram.shape[1] > 1:\n",
        "            #print(f\"Returning zero vector for mel spectrogram size: {file} (shape: {melspectrogram.shape})\")\n",
        "            melspectrogram = np.zeros((128,))  # Return a zero vector of size (128,)\n",
        "\n",
        "        # Check the shape of MFCC coefficients\n",
        "        if mfc_coefficients.ndim > 1 and mfc_coefficients.shape[1] > 1:\n",
        "            #print(f\"Returning zero vector for MFCC size: {file} (shape: {mfc_coefficients.shape})\")\n",
        "            mfc_coefficients = np.zeros((40,))  # Return a zero vector of size (40,)\n",
        "\n",
        "        # use np.hstack to stack our feature arrays horizontally to create a feature matrix\n",
        "        feature_matrix = np.hstack((chromagram, melspectrogram, mfc_coefficients))\n",
        "\n",
        "        return feature_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "c-C6g6psL9hE"
      },
      "source": [
        "### Load the Dataset and Compute Features\n",
        "We have to understand the labelling of the RAVDESS dataset to find the ground truth emotion for each sample.\n",
        "Each file is labelled with 7 numbers delimited by a \"-\".\n",
        "Most of the numbers describe metadata about the audio samples such as their format (video and/or audio),\n",
        "whether the audio is a song or statement, which of two statements is being read and by which actor.\n",
        "\n",
        "The third and fourth numbers pertain to the emotional quality of each sample. The third number is in the range of 1-8 with each number representing an emotion.\n",
        "The fourth number is either 1 or 2, representing normal (1) or strong (2) emotional intensity.\n",
        "\n",
        "We're going to define a dictionary based on the third number (emotion) and assign an emotion to each number as specified by the RAVDESS dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "z-Pu_fB7L9hF"
      },
      "outputs": [],
      "source": [
        "#Emotions in the RAVDESS dataset\n",
        "emotions_dict ={\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pTlsUOwXL9hF"
      },
      "source": [
        "Finally, let's load our entire dataset and compute the features of each audio file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mAh2AYMpL9hF"
      },
      "outputs": [],
      "source": [
        "import os, glob\n",
        "\n",
        "def load_data():\n",
        "    X,y=[],[]\n",
        "    count = 0\n",
        "    # glo glob actor06\n",
        "    for file in glob.glob(\"OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Two/Combined_AudioData/*/*.wav\"):\n",
        "        file_name=os.path.basename(file)\n",
        "        emotion=emotions_dict[file_name.split(\"-\")[2]]\n",
        "        features = get_features(file)\n",
        "        X.append(features)\n",
        "        y.append(emotion)\n",
        "        count += 1\n",
        "        # '\\r' + end='' results in printing over same line\n",
        "        print('\\r' + f' Processed {count}/{1440} audio samples',end=' ')\n",
        "    # Return arrays to plug into sklearn's cross-validation algorithms\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3Cf8q4K5L9hG"
      },
      "source": [
        "Compute the feature matrix and read the emotion labels for the entire dataset.\n",
        "Note that our regressor (independent/explanatory variable), usually denoted X, is named 'features', and our regressand (dependent variable), usually denoted y, is named 'emotions'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "XeKE591aL9hG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be780e6-be4b-4cf3-a98b-b5de9bb7ac28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Processed 1447/1440 audio samples "
          ]
        }
      ],
      "source": [
        "features, emotions = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "RVUa7RAuL9hG"
      },
      "source": [
        "Let's see what the features we extracted look like, **also for saving both the features matrix as well as emotions array, we need to convert them to pandas dataframe.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mzxX583yL9hG",
        "outputId": "2de31ffb-42fd-4f8e-9a0b-4425ff5d40ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Audio samples represented: 1447\n",
            "Numerical features extracted per sample: 180\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0     0.762871  0.786685  0.769217  0.768762  0.773605  0.766615  0.770437   \n",
              "1     0.747417  0.781693  0.774763  0.755513  0.770826  0.783455  0.754270   \n",
              "2     0.767132  0.788347  0.785653  0.786579  0.777644  0.755638  0.761176   \n",
              "3     0.765556  0.760809  0.754814  0.773621  0.797597  0.785697  0.754200   \n",
              "4     0.706621  0.751378  0.765777  0.754597  0.759112  0.770332  0.755594   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1442  0.910119  0.931453  0.948478  0.968992  0.985641  1.000000  0.939519   \n",
              "1443  0.961065  0.971070  0.975175  0.986358  0.993049  1.000000  0.973076   \n",
              "1444  0.952815  0.964700  0.970870  0.983636  0.991913  1.000000  0.967753   \n",
              "1445  0.998305  1.000000  0.994369  0.996455  0.993456  0.992644  0.987887   \n",
              "1446  0.980265  0.986040  0.985445  0.992758  0.995671  1.000000  0.984466   \n",
              "\n",
              "             7         8         9  ...       170       171       172  \\\n",
              "0     0.764894  0.780340  0.761150  ...  0.457082 -1.399110 -2.926856   \n",
              "1     0.748580  0.766922  0.768814  ...  0.275460 -2.521470 -2.987673   \n",
              "2     0.752333  0.774452  0.743741  ... -0.002119 -0.909152 -3.045955   \n",
              "3     0.761343  0.742356  0.725235  ... -0.403806 -1.329651 -2.513405   \n",
              "4     0.741855  0.750051  0.755684  ...  0.206463 -2.188582 -2.835501   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1442  0.811663  0.819952  0.841987  ...  0.000000  0.000000  0.000000   \n",
              "1443  0.913444  0.918203  0.927913  ... -0.021650 -0.033125 -0.029361   \n",
              "1444  0.897324  0.902518  0.914069  ...  0.000000  0.000000  0.000000   \n",
              "1445  0.976810  0.981924  0.985814  ... -0.004858 -0.009785 -0.012539   \n",
              "1446  0.948109  0.952427  0.958658  ... -0.017074 -0.033449 -0.031135   \n",
              "\n",
              "           173       174       175       176       177       178       179  \n",
              "0     0.013957 -0.490734 -0.570906  0.040399 -1.207218 -1.594982 -1.436487  \n",
              "1     0.409735 -0.484184 -1.398391  0.255204 -0.984978 -2.093061 -1.040791  \n",
              "2    -0.373294 -0.849145 -0.922105 -0.170320 -1.144422 -1.725612 -1.450560  \n",
              "3    -0.190276 -0.645949 -0.553919  0.459299 -1.580085 -1.647682 -1.509511  \n",
              "4     0.463746 -1.019167 -1.411440  0.350433 -1.519892 -1.250112 -0.613852  \n",
              "...        ...       ...       ...       ...       ...       ...       ...  \n",
              "1442  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1443 -0.065405 -0.038435 -0.037539 -0.027649 -0.032920 -0.046871 -0.031217  \n",
              "1444  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
              "1445 -0.013049 -0.011774 -0.009466 -0.006945 -0.004890 -0.003716 -0.003570  \n",
              "1446 -0.063867 -0.037307 -0.043111 -0.016950 -0.048487 -0.027693 -0.052255  \n",
              "\n",
              "[1447 rows x 180 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.762871</td>\n",
              "      <td>0.786685</td>\n",
              "      <td>0.769217</td>\n",
              "      <td>0.768762</td>\n",
              "      <td>0.773605</td>\n",
              "      <td>0.766615</td>\n",
              "      <td>0.770437</td>\n",
              "      <td>0.764894</td>\n",
              "      <td>0.780340</td>\n",
              "      <td>0.761150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.457082</td>\n",
              "      <td>-1.399110</td>\n",
              "      <td>-2.926856</td>\n",
              "      <td>0.013957</td>\n",
              "      <td>-0.490734</td>\n",
              "      <td>-0.570906</td>\n",
              "      <td>0.040399</td>\n",
              "      <td>-1.207218</td>\n",
              "      <td>-1.594982</td>\n",
              "      <td>-1.436487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.747417</td>\n",
              "      <td>0.781693</td>\n",
              "      <td>0.774763</td>\n",
              "      <td>0.755513</td>\n",
              "      <td>0.770826</td>\n",
              "      <td>0.783455</td>\n",
              "      <td>0.754270</td>\n",
              "      <td>0.748580</td>\n",
              "      <td>0.766922</td>\n",
              "      <td>0.768814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275460</td>\n",
              "      <td>-2.521470</td>\n",
              "      <td>-2.987673</td>\n",
              "      <td>0.409735</td>\n",
              "      <td>-0.484184</td>\n",
              "      <td>-1.398391</td>\n",
              "      <td>0.255204</td>\n",
              "      <td>-0.984978</td>\n",
              "      <td>-2.093061</td>\n",
              "      <td>-1.040791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.767132</td>\n",
              "      <td>0.788347</td>\n",
              "      <td>0.785653</td>\n",
              "      <td>0.786579</td>\n",
              "      <td>0.777644</td>\n",
              "      <td>0.755638</td>\n",
              "      <td>0.761176</td>\n",
              "      <td>0.752333</td>\n",
              "      <td>0.774452</td>\n",
              "      <td>0.743741</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002119</td>\n",
              "      <td>-0.909152</td>\n",
              "      <td>-3.045955</td>\n",
              "      <td>-0.373294</td>\n",
              "      <td>-0.849145</td>\n",
              "      <td>-0.922105</td>\n",
              "      <td>-0.170320</td>\n",
              "      <td>-1.144422</td>\n",
              "      <td>-1.725612</td>\n",
              "      <td>-1.450560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.765556</td>\n",
              "      <td>0.760809</td>\n",
              "      <td>0.754814</td>\n",
              "      <td>0.773621</td>\n",
              "      <td>0.797597</td>\n",
              "      <td>0.785697</td>\n",
              "      <td>0.754200</td>\n",
              "      <td>0.761343</td>\n",
              "      <td>0.742356</td>\n",
              "      <td>0.725235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403806</td>\n",
              "      <td>-1.329651</td>\n",
              "      <td>-2.513405</td>\n",
              "      <td>-0.190276</td>\n",
              "      <td>-0.645949</td>\n",
              "      <td>-0.553919</td>\n",
              "      <td>0.459299</td>\n",
              "      <td>-1.580085</td>\n",
              "      <td>-1.647682</td>\n",
              "      <td>-1.509511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.706621</td>\n",
              "      <td>0.751378</td>\n",
              "      <td>0.765777</td>\n",
              "      <td>0.754597</td>\n",
              "      <td>0.759112</td>\n",
              "      <td>0.770332</td>\n",
              "      <td>0.755594</td>\n",
              "      <td>0.741855</td>\n",
              "      <td>0.750051</td>\n",
              "      <td>0.755684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.206463</td>\n",
              "      <td>-2.188582</td>\n",
              "      <td>-2.835501</td>\n",
              "      <td>0.463746</td>\n",
              "      <td>-1.019167</td>\n",
              "      <td>-1.411440</td>\n",
              "      <td>0.350433</td>\n",
              "      <td>-1.519892</td>\n",
              "      <td>-1.250112</td>\n",
              "      <td>-0.613852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1442</th>\n",
              "      <td>0.910119</td>\n",
              "      <td>0.931453</td>\n",
              "      <td>0.948478</td>\n",
              "      <td>0.968992</td>\n",
              "      <td>0.985641</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.939519</td>\n",
              "      <td>0.811663</td>\n",
              "      <td>0.819952</td>\n",
              "      <td>0.841987</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1443</th>\n",
              "      <td>0.961065</td>\n",
              "      <td>0.971070</td>\n",
              "      <td>0.975175</td>\n",
              "      <td>0.986358</td>\n",
              "      <td>0.993049</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.973076</td>\n",
              "      <td>0.913444</td>\n",
              "      <td>0.918203</td>\n",
              "      <td>0.927913</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.021650</td>\n",
              "      <td>-0.033125</td>\n",
              "      <td>-0.029361</td>\n",
              "      <td>-0.065405</td>\n",
              "      <td>-0.038435</td>\n",
              "      <td>-0.037539</td>\n",
              "      <td>-0.027649</td>\n",
              "      <td>-0.032920</td>\n",
              "      <td>-0.046871</td>\n",
              "      <td>-0.031217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1444</th>\n",
              "      <td>0.952815</td>\n",
              "      <td>0.964700</td>\n",
              "      <td>0.970870</td>\n",
              "      <td>0.983636</td>\n",
              "      <td>0.991913</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.967753</td>\n",
              "      <td>0.897324</td>\n",
              "      <td>0.902518</td>\n",
              "      <td>0.914069</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1445</th>\n",
              "      <td>0.998305</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994369</td>\n",
              "      <td>0.996455</td>\n",
              "      <td>0.993456</td>\n",
              "      <td>0.992644</td>\n",
              "      <td>0.987887</td>\n",
              "      <td>0.976810</td>\n",
              "      <td>0.981924</td>\n",
              "      <td>0.985814</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.004858</td>\n",
              "      <td>-0.009785</td>\n",
              "      <td>-0.012539</td>\n",
              "      <td>-0.013049</td>\n",
              "      <td>-0.011774</td>\n",
              "      <td>-0.009466</td>\n",
              "      <td>-0.006945</td>\n",
              "      <td>-0.004890</td>\n",
              "      <td>-0.003716</td>\n",
              "      <td>-0.003570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1446</th>\n",
              "      <td>0.980265</td>\n",
              "      <td>0.986040</td>\n",
              "      <td>0.985445</td>\n",
              "      <td>0.992758</td>\n",
              "      <td>0.995671</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.984466</td>\n",
              "      <td>0.948109</td>\n",
              "      <td>0.952427</td>\n",
              "      <td>0.958658</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.017074</td>\n",
              "      <td>-0.033449</td>\n",
              "      <td>-0.031135</td>\n",
              "      <td>-0.063867</td>\n",
              "      <td>-0.037307</td>\n",
              "      <td>-0.043111</td>\n",
              "      <td>-0.016950</td>\n",
              "      <td>-0.048487</td>\n",
              "      <td>-0.027693</td>\n",
              "      <td>-0.052255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1447 rows Ã— 180 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "print(f'\\nAudio samples represented: {features.shape[0]}')\n",
        "print(f'Numerical features extracted per sample: {features.shape[1]}')\n",
        "features_df = pd.DataFrame(features) # make it pretty for display\n",
        "\n",
        "#making dataframe for emotions as well\n",
        "emotions_df = pd.DataFrame(emotions) # make it pretty for display\n",
        "\n",
        "features_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Tq083zLEL9hH"
      },
      "source": [
        "We have a matrix of dim 1435 x 180. Looks good - 1435 audio samples, one per row, with a series of\n",
        "180 numerical features for each sample.\n",
        "\n",
        "**Each of the 1435 feature arrays has 180 features composed of 12 chromagram pitch classes + 128 mel spectrogram bands + 40 MFC coefficients.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will save our features matrix and emotions array in excel file we dont have to compute them everytime we run the notebook, we can just load them from the excel file whenever required. Make sure to change the path to according to your drive."
      ],
      "metadata": {
        "id": "VF2SggHTDqbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features_df.to_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/MY_featuresRavdess.csv')\n",
        "# emotions_df.to_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/MY_emotionsRavdess.csv')\n",
        "\n",
        "# features_df.to_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/featuresRavdess.csv')\n",
        "# emotions_df.to_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/emotionsRavdess.csv')\n",
        "\n",
        "features_df.to_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/featuresOwnRecs.csv')\n",
        "emotions_df.to_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/emotionsOwnRecs.csv')\n"
      ],
      "metadata": {
        "id": "u6H8hc6gDtbp"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load pre-saved Dataset"
      ],
      "metadata": {
        "id": "VpE5m-5aEyoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once saved you only need to load them later by running the cell below, and **skip every cell above** except for the one in which we import libraries."
      ],
      "metadata": {
        "id": "hHPB7dCqEotR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features=pd.read_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/MY_featuresRavdess.csv',index_col=0)\n",
        "# emotions=pd.read_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/MY_emotionsRavdess.csv',index_col=0)\n",
        "\n",
        "# features=pd.read_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/featuresRavdess.csv',index_col=0)\n",
        "# emotions=pd.read_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/emotionsRavdess.csv',index_col=0)\n",
        "\n",
        "features=pd.read_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/featuresOwnRecs.csv',index_col=0)\n",
        "emotions=pd.read_csv('OneDrive/Documents/SFU SIAT/IAT360/Labs/Week Three/emotionsOwnRecs.csv',index_col=0)"
      ],
      "metadata": {
        "id": "-8nlJCESEn56"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "let's see if they have been loaded correctly!"
      ],
      "metadata": {
        "id": "4x2dXjybD1NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features.head()"
      ],
      "metadata": {
        "id": "B5Xo1SVMD0qR",
        "outputId": "88ed713d-30ce-4a7f-85e7-e2c28bae6906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          0         1         2         3         4         5         6  \\\n",
              "0  0.762871  0.786685  0.769217  0.768762  0.773605  0.766615  0.770437   \n",
              "1  0.747417  0.781693  0.774763  0.755513  0.770826  0.783455  0.754270   \n",
              "2  0.767132  0.788347  0.785653  0.786579  0.777644  0.755638  0.761176   \n",
              "3  0.765556  0.760809  0.754814  0.773621  0.797597  0.785697  0.754200   \n",
              "4  0.706621  0.751378  0.765777  0.754597  0.759112  0.770332  0.755594   \n",
              "\n",
              "          7         8         9  ...       170       171       172       173  \\\n",
              "0  0.764894  0.780340  0.761150  ...  0.457082 -1.399110 -2.926856  0.013957   \n",
              "1  0.748580  0.766922  0.768814  ...  0.275460 -2.521470 -2.987673  0.409735   \n",
              "2  0.752333  0.774452  0.743741  ... -0.002119 -0.909152 -3.045955 -0.373294   \n",
              "3  0.761343  0.742356  0.725235  ... -0.403806 -1.329651 -2.513405 -0.190276   \n",
              "4  0.741855  0.750051  0.755684  ...  0.206463 -2.188582 -2.835501  0.463746   \n",
              "\n",
              "        174       175       176       177       178       179  \n",
              "0 -0.490734 -0.570906  0.040399 -1.207218 -1.594982 -1.436487  \n",
              "1 -0.484184 -1.398391  0.255204 -0.984978 -2.093061 -1.040791  \n",
              "2 -0.849145 -0.922105 -0.170320 -1.144422 -1.725612 -1.450560  \n",
              "3 -0.645949 -0.553919  0.459299 -1.580085 -1.647682 -1.509511  \n",
              "4 -1.019167 -1.411440  0.350433 -1.519892 -1.250112 -0.613852  \n",
              "\n",
              "[5 rows x 180 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.762871</td>\n",
              "      <td>0.786685</td>\n",
              "      <td>0.769217</td>\n",
              "      <td>0.768762</td>\n",
              "      <td>0.773605</td>\n",
              "      <td>0.766615</td>\n",
              "      <td>0.770437</td>\n",
              "      <td>0.764894</td>\n",
              "      <td>0.780340</td>\n",
              "      <td>0.761150</td>\n",
              "      <td>...</td>\n",
              "      <td>0.457082</td>\n",
              "      <td>-1.399110</td>\n",
              "      <td>-2.926856</td>\n",
              "      <td>0.013957</td>\n",
              "      <td>-0.490734</td>\n",
              "      <td>-0.570906</td>\n",
              "      <td>0.040399</td>\n",
              "      <td>-1.207218</td>\n",
              "      <td>-1.594982</td>\n",
              "      <td>-1.436487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.747417</td>\n",
              "      <td>0.781693</td>\n",
              "      <td>0.774763</td>\n",
              "      <td>0.755513</td>\n",
              "      <td>0.770826</td>\n",
              "      <td>0.783455</td>\n",
              "      <td>0.754270</td>\n",
              "      <td>0.748580</td>\n",
              "      <td>0.766922</td>\n",
              "      <td>0.768814</td>\n",
              "      <td>...</td>\n",
              "      <td>0.275460</td>\n",
              "      <td>-2.521470</td>\n",
              "      <td>-2.987673</td>\n",
              "      <td>0.409735</td>\n",
              "      <td>-0.484184</td>\n",
              "      <td>-1.398391</td>\n",
              "      <td>0.255204</td>\n",
              "      <td>-0.984978</td>\n",
              "      <td>-2.093061</td>\n",
              "      <td>-1.040791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.767132</td>\n",
              "      <td>0.788347</td>\n",
              "      <td>0.785653</td>\n",
              "      <td>0.786579</td>\n",
              "      <td>0.777644</td>\n",
              "      <td>0.755638</td>\n",
              "      <td>0.761176</td>\n",
              "      <td>0.752333</td>\n",
              "      <td>0.774452</td>\n",
              "      <td>0.743741</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002119</td>\n",
              "      <td>-0.909152</td>\n",
              "      <td>-3.045955</td>\n",
              "      <td>-0.373294</td>\n",
              "      <td>-0.849145</td>\n",
              "      <td>-0.922105</td>\n",
              "      <td>-0.170320</td>\n",
              "      <td>-1.144422</td>\n",
              "      <td>-1.725612</td>\n",
              "      <td>-1.450560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.765556</td>\n",
              "      <td>0.760809</td>\n",
              "      <td>0.754814</td>\n",
              "      <td>0.773621</td>\n",
              "      <td>0.797597</td>\n",
              "      <td>0.785697</td>\n",
              "      <td>0.754200</td>\n",
              "      <td>0.761343</td>\n",
              "      <td>0.742356</td>\n",
              "      <td>0.725235</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.403806</td>\n",
              "      <td>-1.329651</td>\n",
              "      <td>-2.513405</td>\n",
              "      <td>-0.190276</td>\n",
              "      <td>-0.645949</td>\n",
              "      <td>-0.553919</td>\n",
              "      <td>0.459299</td>\n",
              "      <td>-1.580085</td>\n",
              "      <td>-1.647682</td>\n",
              "      <td>-1.509511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.706621</td>\n",
              "      <td>0.751378</td>\n",
              "      <td>0.765777</td>\n",
              "      <td>0.754597</td>\n",
              "      <td>0.759112</td>\n",
              "      <td>0.770332</td>\n",
              "      <td>0.755594</td>\n",
              "      <td>0.741855</td>\n",
              "      <td>0.750051</td>\n",
              "      <td>0.755684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.206463</td>\n",
              "      <td>-2.188582</td>\n",
              "      <td>-2.835501</td>\n",
              "      <td>0.463746</td>\n",
              "      <td>-1.019167</td>\n",
              "      <td>-1.411440</td>\n",
              "      <td>0.350433</td>\n",
              "      <td>-1.519892</td>\n",
              "      <td>-1.250112</td>\n",
              "      <td>-0.613852</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 180 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esInVDq7L9hT"
      },
      "source": [
        "Let's see the class balance of our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "Si3OFQe7L9hU",
        "outputId": "beb8b537-8742-4916-8e25-499833227917",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 3500x400 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot emotions\n",
        "plt.figure(figsize=(35,4))\n",
        "plt.subplot(1,3,1)\n",
        "#np.unique returns ordered list of unique elements and count of each element\n",
        "emotion_list, count = np.unique(emotions, return_counts=True)\n",
        "plt.bar(x=range(8), height=count)\n",
        "plt.xticks(ticks=range(8), labels = [emotion for emotion in emotion_list],fontsize=10)\n",
        "plt.xlabel('Emotion')\n",
        "plt.tick_params(labelsize=16)\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw_wKC8WL9hV"
      },
      "source": [
        "**Great, the classes appear to be balanced. That makes the task easier.** All emotions _except_ the neutral class have a \"strong\" intensity so there are half as many neutral samples. That might have an impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhtlYshOL9hV"
      },
      "source": [
        "### Feature Scaling\n",
        "To properly train most machine learning models on _most_ datasets, we first need to scale our features. **This is crucial for models which compute distances between data, and especially critical for DNNs**: If there is a difference in the variance of features simply because of their possible range of values, then a model will learn that the features with the greatest variance are the most important. However, **differences in the variance of unscaled features belonging to different and unknown distributions is an inappropriate measure of importance.** Let's check our features' properties:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# used to get statistics\n",
        "# not very useful in this case\n",
        "features.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ZThHnEpq69Zd",
        "outputId": "66719393-324b-450e-e205-b77bcea2773e"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0            1            2            3            4  \\\n",
              "count  1447.000000  1447.000000  1447.000000  1447.000000  1447.000000   \n",
              "mean      0.651761     0.646134     0.649449     0.657352     0.673888   \n",
              "std       0.082886     0.092237     0.096166     0.097518     0.098485   \n",
              "min       0.378328     0.340238     0.310377     0.331314     0.390025   \n",
              "25%       0.599544     0.583602     0.581602     0.586450     0.600658   \n",
              "50%       0.655370     0.650411     0.655676     0.669413     0.692124   \n",
              "75%       0.707456     0.714635     0.721009     0.729014     0.747346   \n",
              "max       0.999220     1.000000     0.994369     0.996455     0.997027   \n",
              "\n",
              "                 5            6            7            8            9  ...  \\\n",
              "count  1447.000000  1447.000000  1447.000000  1447.000000  1447.000000  ...   \n",
              "mean      0.684064     0.687301     0.678107     0.681788     0.673718  ...   \n",
              "std       0.093802     0.088458     0.084684     0.083964     0.083107  ...   \n",
              "min       0.378070     0.350047     0.363718     0.406125     0.414586  ...   \n",
              "25%       0.618174     0.624843     0.621719     0.624206     0.620275  ...   \n",
              "50%       0.703243     0.703930     0.691741     0.695954     0.687612  ...   \n",
              "75%       0.750231     0.749073     0.739047     0.743519     0.731888  ...   \n",
              "max       1.000000     0.988813     0.978808     0.985013     0.988497  ...   \n",
              "\n",
              "               170          171          172          173          174  \\\n",
              "count  1447.000000  1447.000000  1447.000000  1447.000000  1447.000000   \n",
              "mean     -0.329824     0.338474    -0.259853     0.640087     0.539924   \n",
              "std       2.219184     2.321241     2.178211     2.080207     2.011472   \n",
              "min      -5.994779    -4.969791    -5.206000    -4.321074    -4.948631   \n",
              "25%      -1.758035    -1.166879    -1.687009    -0.752880    -0.785146   \n",
              "50%      -0.545024     0.014425    -0.444368     0.367684     0.224907   \n",
              "75%       0.750067     1.500370     0.923816     1.738341     1.649303   \n",
              "max      12.655916    14.277499    10.516112    11.420576     9.299726   \n",
              "\n",
              "               175          176          177          178          179  \n",
              "count  1447.000000  1447.000000  1447.000000  1447.000000  1447.000000  \n",
              "mean      0.485504     0.561155     0.689938     0.414661     0.888263  \n",
              "std       1.982050     1.930550     1.891655     1.954451     1.994941  \n",
              "min      -6.151188    -5.380692    -4.377184    -4.573127    -4.713404  \n",
              "25%      -0.790292    -0.776649    -0.560878    -0.953046    -0.478770  \n",
              "50%       0.205461     0.364894     0.518952     0.132383     0.605703  \n",
              "75%       1.724412     1.650879     1.789056     1.567353     2.027913  \n",
              "max       8.715325    10.268682     9.382309     9.480828    10.302836  \n",
              "\n",
              "[8 rows x 180 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>170</th>\n",
              "      <th>171</th>\n",
              "      <th>172</th>\n",
              "      <th>173</th>\n",
              "      <th>174</th>\n",
              "      <th>175</th>\n",
              "      <th>176</th>\n",
              "      <th>177</th>\n",
              "      <th>178</th>\n",
              "      <th>179</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "      <td>1447.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.651761</td>\n",
              "      <td>0.646134</td>\n",
              "      <td>0.649449</td>\n",
              "      <td>0.657352</td>\n",
              "      <td>0.673888</td>\n",
              "      <td>0.684064</td>\n",
              "      <td>0.687301</td>\n",
              "      <td>0.678107</td>\n",
              "      <td>0.681788</td>\n",
              "      <td>0.673718</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.329824</td>\n",
              "      <td>0.338474</td>\n",
              "      <td>-0.259853</td>\n",
              "      <td>0.640087</td>\n",
              "      <td>0.539924</td>\n",
              "      <td>0.485504</td>\n",
              "      <td>0.561155</td>\n",
              "      <td>0.689938</td>\n",
              "      <td>0.414661</td>\n",
              "      <td>0.888263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.082886</td>\n",
              "      <td>0.092237</td>\n",
              "      <td>0.096166</td>\n",
              "      <td>0.097518</td>\n",
              "      <td>0.098485</td>\n",
              "      <td>0.093802</td>\n",
              "      <td>0.088458</td>\n",
              "      <td>0.084684</td>\n",
              "      <td>0.083964</td>\n",
              "      <td>0.083107</td>\n",
              "      <td>...</td>\n",
              "      <td>2.219184</td>\n",
              "      <td>2.321241</td>\n",
              "      <td>2.178211</td>\n",
              "      <td>2.080207</td>\n",
              "      <td>2.011472</td>\n",
              "      <td>1.982050</td>\n",
              "      <td>1.930550</td>\n",
              "      <td>1.891655</td>\n",
              "      <td>1.954451</td>\n",
              "      <td>1.994941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.378328</td>\n",
              "      <td>0.340238</td>\n",
              "      <td>0.310377</td>\n",
              "      <td>0.331314</td>\n",
              "      <td>0.390025</td>\n",
              "      <td>0.378070</td>\n",
              "      <td>0.350047</td>\n",
              "      <td>0.363718</td>\n",
              "      <td>0.406125</td>\n",
              "      <td>0.414586</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.994779</td>\n",
              "      <td>-4.969791</td>\n",
              "      <td>-5.206000</td>\n",
              "      <td>-4.321074</td>\n",
              "      <td>-4.948631</td>\n",
              "      <td>-6.151188</td>\n",
              "      <td>-5.380692</td>\n",
              "      <td>-4.377184</td>\n",
              "      <td>-4.573127</td>\n",
              "      <td>-4.713404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.599544</td>\n",
              "      <td>0.583602</td>\n",
              "      <td>0.581602</td>\n",
              "      <td>0.586450</td>\n",
              "      <td>0.600658</td>\n",
              "      <td>0.618174</td>\n",
              "      <td>0.624843</td>\n",
              "      <td>0.621719</td>\n",
              "      <td>0.624206</td>\n",
              "      <td>0.620275</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.758035</td>\n",
              "      <td>-1.166879</td>\n",
              "      <td>-1.687009</td>\n",
              "      <td>-0.752880</td>\n",
              "      <td>-0.785146</td>\n",
              "      <td>-0.790292</td>\n",
              "      <td>-0.776649</td>\n",
              "      <td>-0.560878</td>\n",
              "      <td>-0.953046</td>\n",
              "      <td>-0.478770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.655370</td>\n",
              "      <td>0.650411</td>\n",
              "      <td>0.655676</td>\n",
              "      <td>0.669413</td>\n",
              "      <td>0.692124</td>\n",
              "      <td>0.703243</td>\n",
              "      <td>0.703930</td>\n",
              "      <td>0.691741</td>\n",
              "      <td>0.695954</td>\n",
              "      <td>0.687612</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.545024</td>\n",
              "      <td>0.014425</td>\n",
              "      <td>-0.444368</td>\n",
              "      <td>0.367684</td>\n",
              "      <td>0.224907</td>\n",
              "      <td>0.205461</td>\n",
              "      <td>0.364894</td>\n",
              "      <td>0.518952</td>\n",
              "      <td>0.132383</td>\n",
              "      <td>0.605703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.707456</td>\n",
              "      <td>0.714635</td>\n",
              "      <td>0.721009</td>\n",
              "      <td>0.729014</td>\n",
              "      <td>0.747346</td>\n",
              "      <td>0.750231</td>\n",
              "      <td>0.749073</td>\n",
              "      <td>0.739047</td>\n",
              "      <td>0.743519</td>\n",
              "      <td>0.731888</td>\n",
              "      <td>...</td>\n",
              "      <td>0.750067</td>\n",
              "      <td>1.500370</td>\n",
              "      <td>0.923816</td>\n",
              "      <td>1.738341</td>\n",
              "      <td>1.649303</td>\n",
              "      <td>1.724412</td>\n",
              "      <td>1.650879</td>\n",
              "      <td>1.789056</td>\n",
              "      <td>1.567353</td>\n",
              "      <td>2.027913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.999220</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994369</td>\n",
              "      <td>0.996455</td>\n",
              "      <td>0.997027</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.988813</td>\n",
              "      <td>0.978808</td>\n",
              "      <td>0.985013</td>\n",
              "      <td>0.988497</td>\n",
              "      <td>...</td>\n",
              "      <td>12.655916</td>\n",
              "      <td>14.277499</td>\n",
              "      <td>10.516112</td>\n",
              "      <td>11.420576</td>\n",
              "      <td>9.299726</td>\n",
              "      <td>8.715325</td>\n",
              "      <td>10.268682</td>\n",
              "      <td>9.382309</td>\n",
              "      <td>9.480828</td>\n",
              "      <td>10.302836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows Ã— 180 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "_IUm1DLwL9hW",
        "outputId": "c985f8be-5ee9-4ddd-ea18-df61417e4bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mBefore Scaling:\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "cannot do slice indexing on Index with these indexers [11] of type int",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m40 MFCC features:             \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[33m    min = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmfcc_min\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[33m    max = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmfcc_max\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[33m    mean = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmfcc_mean\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33m    deviation = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmfcc_stdev\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[33m[1m\u001b[39m\u001b[33m'\u001b[39m+\u001b[33m'\u001b[39m\u001b[33mBefore Scaling:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m+\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\033\u001b[39;00m\u001b[33m[0m\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mprint_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mprint_features\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprint_features\u001b[39m(df):\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Check chromagram feature values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     features_df_chromagram = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m11\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m     chroma_min = features_df_chromagram.min().min()\n\u001b[32m      6\u001b[39m     chroma_max = features_df_chromagram.max().max()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1184\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m   1183\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._get_value(*key, takeable=\u001b[38;5;28mself\u001b[39m._takeable)\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[32m   1187\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1377\u001b[39m, in \u001b[36m_LocIndexer._getitem_tuple\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_take_opportunity(tup):\n\u001b[32m   1375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._multi_take(tup)\n\u001b[32m-> \u001b[39m\u001b[32m1377\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple_same_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1020\u001b[39m, in \u001b[36m_LocationIndexer._getitem_tuple_same_dim\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m com.is_null_slice(key):\n\u001b[32m   1018\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1020\u001b[39m retval = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mretval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[38;5;66;03m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[38;5;66;03m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m retval.ndim == \u001b[38;5;28mself\u001b[39m.ndim\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1411\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1409\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   1410\u001b[39m     \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_slice_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getbool_axis(key, axis=axis)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1443\u001b[39m, in \u001b[36m_LocIndexer._get_slice_axis\u001b[39m\u001b[34m(self, slice_obj, axis)\u001b[39m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1442\u001b[39m labels = obj._get_axis(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m indexer = \u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mslice_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._slice(indexer, axis=axis)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6708\u001b[39m, in \u001b[36mIndex.slice_indexer\u001b[39m\u001b[34m(self, start, end, step)\u001b[39m\n\u001b[32m   6664\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mslice_indexer\u001b[39m(\n\u001b[32m   6665\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   6666\u001b[39m     start: Hashable | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   6667\u001b[39m     end: Hashable | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   6668\u001b[39m     step: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   6669\u001b[39m ) -> \u001b[38;5;28mslice\u001b[39m:\n\u001b[32m   6670\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   6671\u001b[39m \u001b[33;03m    Compute the slice indexer for input labels and step.\u001b[39;00m\n\u001b[32m   6672\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   6706\u001b[39m \u001b[33;03m    slice(1, 3, None)\u001b[39;00m\n\u001b[32m   6707\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6708\u001b[39m     start_slice, end_slice = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mslice_locs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6710\u001b[39m     \u001b[38;5;66;03m# return a slice\u001b[39;00m\n\u001b[32m   6711\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(start_slice):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6940\u001b[39m, in \u001b[36mIndex.slice_locs\u001b[39m\u001b[34m(self, start, end, step)\u001b[39m\n\u001b[32m   6938\u001b[39m end_slice = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   6939\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6940\u001b[39m     end_slice = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mright\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   6941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end_slice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   6942\u001b[39m     end_slice = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6849\u001b[39m, in \u001b[36mIndex.get_slice_bound\u001b[39m\u001b[34m(self, label, side)\u001b[39m\n\u001b[32m   6845\u001b[39m original_label = label\n\u001b[32m   6847\u001b[39m \u001b[38;5;66;03m# For datetime indices label may be a string that has to be converted\u001b[39;00m\n\u001b[32m   6848\u001b[39m \u001b[38;5;66;03m# to datetime boundary according to its resolution.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6849\u001b[39m label = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_cast_slice_bound\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6851\u001b[39m \u001b[38;5;66;03m# we need to look up the label\u001b[39;00m\n\u001b[32m   6852\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6782\u001b[39m, in \u001b[36mIndex._maybe_cast_slice_bound\u001b[39m\u001b[34m(self, label, side)\u001b[39m\n\u001b[32m   6780\u001b[39m \u001b[38;5;66;03m# reject them, if index does not contain label\u001b[39;00m\n\u001b[32m   6781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (is_float(label) \u001b[38;5;129;01mor\u001b[39;00m is_integer(label)) \u001b[38;5;129;01mand\u001b[39;00m label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m6782\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_invalid_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mslice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6784\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m label\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4308\u001b[39m, in \u001b[36mIndex._raise_invalid_indexer\u001b[39m\u001b[34m(self, form, key, reraise)\u001b[39m\n\u001b[32m   4306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reraise \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m   4307\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4308\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
            "\u001b[31mTypeError\u001b[39m: cannot do slice indexing on Index with these indexers [11] of type int"
          ]
        }
      ],
      "source": [
        "# We would usually use df.describe(), but it provides a bit of a mess of information we don't need at the moment.\n",
        "def print_features(df):\n",
        "    # Check chromagram feature values\n",
        "    features_df_chromagram = df.loc[:,:11]\n",
        "    chroma_min = features_df_chromagram.min().min()\n",
        "    chroma_max = features_df_chromagram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    chroma_mean = features_df_chromagram.stack().mean()\n",
        "    chroma_stdev = features_df_chromagram.stack().std()\n",
        "    print(f'12 Chromagram features:       \\\n",
        "    min = {chroma_min:.3f}, \\\n",
        "    max = {chroma_max:.3f}, \\\n",
        "    mean = {chroma_mean:.3f}, \\\n",
        "    deviation = {chroma_stdev:.3f}')\n",
        "\n",
        "    # Check mel spectrogram feature values\n",
        "    features_df_melspectrogram = df.loc[:,12:139]\n",
        "    mel_min = features_df_melspectrogram.min().min()\n",
        "    mel_max = features_df_melspectrogram.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mel_mean = features_df_melspectrogram.stack().mean()\n",
        "    mel_stdev = features_df_melspectrogram.stack().std()\n",
        "    print(f'\\n128 Mel Spectrogram features: \\\n",
        "    min = {mel_min:.3f}, \\\n",
        "    max = {mel_max:.3f}, \\\n",
        "    mean = {mel_mean:.3f}, \\\n",
        "    deviation = {mel_stdev:.3f}')\n",
        "\n",
        "    # Check MFCC feature values\n",
        "    features_df_mfcc = df.loc[:,140:179]\n",
        "    mfcc_min = features_df_mfcc.min().min()\n",
        "    mfcc_max = features_df_mfcc.max().max()\n",
        "    # stack all features into a single series so we don't get a mean of means or stdev of stdevs\n",
        "    mfcc_mean = features_df_mfcc.stack().mean()\n",
        "    mfcc_stdev = features_df_mfcc.stack().std()\n",
        "    print(f'\\n40 MFCC features:             \\\n",
        "    min = {mfcc_min:.3f},\\\n",
        "    max = {mfcc_max:.3f},\\\n",
        "    mean = {mfcc_mean:.3f},\\\n",
        "    deviation = {mfcc_stdev:.3f}')\n",
        "\n",
        "print('\\033[1m'+'Before Scaling:\\n'+'\\033[0m')\n",
        "print_features(features_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ha1FxBSCpqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFgQlYSlL9hW"
      },
      "source": [
        "**There's an obvious imbalance in the variance our features; Our features indeed belong to very different distributions:** our MFC coefficients' deviation is greater than the other features by orders of magnitude. That does not mean MFC coefficients are the most important feature, but rather it is a property of the way they are computed.  We will certainly need to scale this feature set.\n",
        "\n",
        "We have the choice of sklearn's StandardScaler and MinMaxScaler. Standard scaling subtracts the mean of each feature and divides it by the standard deviation of that feature, producing features with mean at zero and unit variance - that is, a variance and standard deviation of 1. Min-Max scaling transforms each feature to be within a bounded interval that we specify.\n",
        "\n",
        "In practice, **MinMax scaling is especially useful when we know our features should be in a bounded interval**, such as pixel values in [0,255], while **standard scaling is perhaps more practical for features with unknown distributions** because centering the features at zero-mean with a standard deviation of 1 means extreme values will have less of an impact on the model's learned weights, i.e. the model is less sensitive to outliers.\n",
        "\n",
        "We'll create MinMax scaled features as well so we can give them a try later on to confirm that standard scaling is better in the absence of knowledge on the appropriate distribution for a dataset's features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "_BCAYVEUL9hW"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# keep our unscaled features just in case we need to process them alternatively\n",
        "features_scaled = features.copy()\n",
        "features_scaled = scaler.fit_transform(features_scaled)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "# keep our unscaled features just in case we need to process them alternatively\n",
        "features_minmax = features.copy()\n",
        "features_minmax = scaler.fit_transform(features_minmax)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ATx5oNL9hX"
      },
      "source": [
        "Make sure our features are properly scaled:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "mlRuHQkKL9hX",
        "outputId": "4f34e91c-2f52-4f3e-fa13-534350086339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mStandard Scaling:\n",
            "\u001b[0m\n",
            "12 Chromagram features:           min = -3.896,     max = 4.368,     mean = -0.000,     deviation = 1.000\n",
            "\n",
            "128 Mel Spectrogram features:     min = -0.474,     max = 36.531,     mean = 0.000,     deviation = 1.000\n",
            "\n",
            "40 MFCC features:                 min = -4.803,    max = 6.238,    mean = -0.000,    deviation = 1.000\n",
            "\n",
            "\n",
            "\u001b[1mMinMax Scaling:\n",
            "\u001b[0m\n",
            "12 Chromagram features:           min = 0.000,     max = 1.000,     mean = 0.472,     deviation = 0.145\n",
            "\n",
            "128 Mel Spectrogram features:     min = 0.000,     max = 1.000,     mean = 0.015,     deviation = 0.061\n",
            "\n",
            "40 MFCC features:                 min = 0.000,    max = 1.000,    mean = 0.412,    deviation = 0.169\n"
          ]
        }
      ],
      "source": [
        "print('\\033[1m'+'Standard Scaling:\\n'+'\\033[0m')\n",
        "features_scaled_df = pd.DataFrame(features_scaled)\n",
        "print_features(features_scaled_df)\n",
        "\n",
        "print('\\n\\n\\033[1m'+'MinMax Scaling:\\n'+'\\033[0m')\n",
        "features_minmax_df = pd.DataFrame(features_minmax)\n",
        "print_features(features_minmax_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZfzIh7DL9hX"
      },
      "source": [
        "Perfect. Zero mean and unit variance for standard scaling and in the range [0,1] for MinMax scaling - a default when we don't specify values. We can now move on to building predictive models for these features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5tXewLEL9hX"
      },
      "source": [
        "## Classical Machine Learning Models\n",
        "\n",
        "\n",
        "Classical machine learning models encompass a broad range of algorithms that have been foundational to the field's development and are still widely used for various predictive tasks. These models can be broadly categorized into supervised and unsupervised learning methods, each suited for different kinds of data and objectives.\n",
        "\n",
        "We will be looking into few popular Machine Learning Algorithms such as Support Vector Machine(SVM), K-Nearest Neighbors and Random Forest Classifier. There are many other classical models with their own strengths and weaknesses, and the choice of model depends on the specific requirements of the task, including the nature of the data, the complexity of the problem, and the computational efficiency required. Despite the rise of deep learning, classical machine learning models remain vital tools in a data scientist's arsenal due to their efficiency, interpretability, and strong performance in many scenarios.\n",
        "\n",
        "The use of classic machine learning method is due to the small size of our dataset; Some of the most robust models such as Support vector (machine) classifiers **(SVC) and k-Nearest-Neighbour classifiers (kNN) are particularly suited to smaller datasets and fall apart with huge datasets.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwU-jXSGL9hY"
      },
      "source": [
        "### Training: The 80/20 Split and Validation\n",
        "In order to compare models, we'll have to evaluate their performance. The simplest method to do so is to train a model on a portion of our dataset and test it on the remainder. We'll use sklearn's train_test_split to create a standard 80/20 train/test split. The model is fit on 80% of\n",
        "the data and tested for performance against 20% of the data, which it has never seen in training - also called the hold-out set.\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-Machine_Learning/blob/main/images/Capture2.PNG?raw=true\" width=\"800\">\n",
        "\n",
        "More accurately, the proper modality for training and scoring a model is to\n",
        "1. Fit/train our model on a _training_ set,\n",
        "2. Evaluate the model on a _validation_ set to tune the hyperparameters for better performance,\n",
        "3. Finally score our model's true performance - its **generalizability** - against a _test_ set, aka the hold-out set.\n",
        "4. Repeat from 2. **Do not tune the model to score well on the test set**. Only evaluate on test-set once.\n",
        "\n",
        "Different set ratios are used in this approach - a usual example is 60/20/20 train/validation/test.For simplicity, we're going to start with an 80/20 train/test split. The model will be trained on all the training data, and we will check its performance on the test data. We'll skip validation for now.\n",
        "\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-ClassicML/blob/main/images/traintestsplit.PNG?raw=true\" width=\"800\">\n",
        "\n",
        "Define unscaled and scaled training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "8jGN4ROVL9hY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a3037b7-87a9-4315-cd1c-357d15ea1624"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1439, 1447]",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      5\u001b[39m X_train, X_test, y_train, y_test =train_test_split(\n\u001b[32m      6\u001b[39m     features,\n\u001b[32m      7\u001b[39m     emotions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m############ Standard Scaled test/train set ###########\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# The labels/classes (y_train, y_test) never change, keep old values\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m X_train_scaled, X_test_scaled, _, _ = \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43memotions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m############# MinMax Scaled test/train set ###############\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# The labels/classes (y_train, y_test) never change, keep old values\u001b[39;00m\n\u001b[32m     24\u001b[39m X_train_minmax, X_test_minmax, _, _ = train_test_split(\n\u001b[32m     25\u001b[39m     features_minmax,\n\u001b[32m     26\u001b[39m     emotions,\n\u001b[32m     27\u001b[39m     test_size=\u001b[32m0.2\u001b[39m,\n\u001b[32m     28\u001b[39m     random_state=\u001b[32m42\u001b[39m\n\u001b[32m     29\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2916\u001b[39m, in \u001b[36mtrain_test_split\u001b[39m\u001b[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[39m\n\u001b[32m   2913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_arrays == \u001b[32m0\u001b[39m:\n\u001b[32m   2914\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAt least one array required as input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2916\u001b[39m arrays = \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2918\u001b[39m n_samples = _num_samples(arrays[\u001b[32m0\u001b[39m])\n\u001b[32m   2919\u001b[39m n_train, n_test = _validate_shuffle_split(\n\u001b[32m   2920\u001b[39m     n_samples, test_size, train_size, default_test_size=\u001b[32m0.25\u001b[39m\n\u001b[32m   2921\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:530\u001b[39m, in \u001b[36mindexable\u001b[39m\u001b[34m(*iterables)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[32m    501\u001b[39m \n\u001b[32m    502\u001b[39m \u001b[33;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m \u001b[33;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[32m    527\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    529\u001b[39m result = [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:473\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    471\u001b[39m lengths = [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    472\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(lengths)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    474\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    475\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    476\u001b[39m     )\n",
            "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [1439, 1447]"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "############# Unscaled test/train set #############\n",
        "X_train, X_test, y_train, y_test =train_test_split(\n",
        "    features,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    # always provide consistent number for random state for consistent results\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "############ Standard Scaled test/train set ###########\n",
        "# The labels/classes (y_train, y_test) never change, keep old values\n",
        "X_train_scaled, X_test_scaled, _, _ = train_test_split(\n",
        "    features_scaled,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "############# MinMax Scaled test/train set ###############\n",
        "# The labels/classes (y_train, y_test) never change, keep old values\n",
        "X_train_minmax, X_test_minmax, _, _ = train_test_split(\n",
        "    features_minmax,\n",
        "    emotions,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3Mh0RrEL9hY"
      },
      "source": [
        "### Comparing Models\n",
        "We'll try each off-the-shelf machine learning model from sklearn and pick a few to explore, since these models will train near instantly on this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "scrolled": true,
        "id": "iLPeyR7vL9he",
        "outputId": "3bfe1dee-8e48-4289-a12f-70b6a03a0161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1mStardard Scaling:\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Classifier Accuracy Score\n",
              "0           KNeighborsClassifier         55.90%\n",
              "4         RandomForestClassifier         55.56%\n",
              "1                            SVC         50.35%\n",
              "2                 SVC RBF kernel         50.35%\n",
              "3         DecisionTreeClassifier         34.38%\n",
              "5             AdaBoostClassifier         30.21%\n",
              "6                     GaussianNB         30.21%\n",
              "7  QuadraticDiscriminantAnalysis         27.08%"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>55.90%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>55.56%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVC</td>\n",
              "      <td>50.35%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVC RBF kernel</td>\n",
              "      <td>50.35%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>34.38%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>30.21%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>30.21%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>27.08%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "classification_models = [\n",
        "    KNeighborsClassifier(),#(3),\n",
        "    SVC(kernel='linear'),#, C=0.025),\n",
        "    SVC(kernel='rbf'),\n",
        "    DecisionTreeClassifier(),#max_depth=5),\n",
        "    RandomForestClassifier(),#max_depth=5, n_estimators=10, max_features=1),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "scores = []\n",
        "for model in classification_models:\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    score = model.score(X_test_scaled, y_test)\n",
        "    model_name = type(model).__name__\n",
        "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
        "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
        "# Make it pretty\n",
        "print('\\n\\n\\033[1m'+'Stardard Scaling:\\n'+'\\033[0m')\n",
        "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
        "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "classification_models = [\n",
        "    KNeighborsClassifier(),#(3),\n",
        "    SVC(kernel='linear'),#, C=0.025),\n",
        "    SVC(kernel='rbf'),\n",
        "    DecisionTreeClassifier(),#max_depth=5),\n",
        "    RandomForestClassifier(),#max_depth=5, n_estimators=10, max_features=1),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "# X_train, X_test, y_train, y_test\n",
        "scores = []\n",
        "for model in classification_models:\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_test, y_test)\n",
        "    model_name = type(model).__name__\n",
        "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
        "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
        "# Make it pretty\n",
        "print('\\n\\n\\033[1m'+'No Scaling:\\n'+'\\033[0m')\n",
        "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
        "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "lajuSQLJUbuU",
        "outputId": "70836fc4-7d04-4db6-bb54-a015d3257a03"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1mNo Scaling:\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Classifier Accuracy Score\n",
              "4         RandomForestClassifier         59.38%\n",
              "0           KNeighborsClassifier         51.39%\n",
              "1                            SVC         46.53%\n",
              "3         DecisionTreeClassifier         37.85%\n",
              "6                     GaussianNB         33.33%\n",
              "5             AdaBoostClassifier         30.21%\n",
              "2                 SVC RBF kernel         29.86%\n",
              "7  QuadraticDiscriminantAnalysis         23.96%"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>59.38%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>51.39%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVC</td>\n",
              "      <td>46.53%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>37.85%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>33.33%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>30.21%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVC RBF kernel</td>\n",
              "      <td>29.86%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>23.96%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "classification_models = [\n",
        "    KNeighborsClassifier(),#(3),\n",
        "    SVC(kernel='linear'),#, C=0.025),\n",
        "    SVC(kernel='rbf'),\n",
        "    DecisionTreeClassifier(),#max_depth=5),\n",
        "    RandomForestClassifier(),#max_depth=5, n_estimators=10, max_features=1),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()]\n",
        "\n",
        "# X_train_minmax, X_test_minmax, y_train, y_test\n",
        "scores = []\n",
        "for model in classification_models:\n",
        "    model.fit(X_train_minmax, y_train)\n",
        "    score = model.score(X_test_minmax, y_test)\n",
        "    model_name = type(model).__name__\n",
        "    if model_name=='SVC' and model.kernel=='rbf': model_name+=' RBF kernel'\n",
        "    scores.append((model_name,(f'{100*score:.2f}%')))\n",
        "\n",
        "# Make it pretty\n",
        "print('\\n\\n\\033[1m'+'MinMax Scaling:\\n'+'\\033[0m')\n",
        "scores_df = pd.DataFrame(scores,columns=['Classifier','Accuracy Score'])\n",
        "scores_df.sort_values(by='Accuracy Score',axis=0,ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "xbzU-x5PVWGd",
        "outputId": "9e390a61-9943-41eb-adf8-4ef03179ec3a"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1mMinMax Scaling:\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      Classifier Accuracy Score\n",
              "0           KNeighborsClassifier         59.72%\n",
              "4         RandomForestClassifier         54.86%\n",
              "1                            SVC         50.69%\n",
              "2                 SVC RBF kernel         45.14%\n",
              "3         DecisionTreeClassifier         34.38%\n",
              "5             AdaBoostClassifier         30.21%\n",
              "6                     GaussianNB         30.21%\n",
              "7  QuadraticDiscriminantAnalysis         24.31%"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Classifier</th>\n",
              "      <th>Accuracy Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>KNeighborsClassifier</td>\n",
              "      <td>59.72%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>54.86%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVC</td>\n",
              "      <td>50.69%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SVC RBF kernel</td>\n",
              "      <td>45.14%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>34.38%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>30.21%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GaussianNB</td>\n",
              "      <td>30.21%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>QuadraticDiscriminantAnalysis</td>\n",
              "      <td>24.31%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrD98CpPL9he"
      },
      "source": [
        "Let's pick the top three - Random Forests, SVC, and kNN - and take a closer look at each of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dBNoEolL9hf"
      },
      "source": [
        "### The Support Vector Machine Classifier\n",
        "\n",
        "We'll go in chronological order. First is the support vector machine classifier (SVC) - a model from the 60s. SVMs are models quick to train for this task and best suited to small datasets due to its quadratic time complexity w.r.t. size of the training dataset (# of training samples). This is also the reason it breaks down with larger datasets since it becomes very expensive to train.\n",
        "\n",
        "The idea behind SVMs on which the SVC model is based is to find a separating hyperplane - a subspace with dimension one less than that of the feature space - for points in our feature space; i.e. for a 3D space, a hyperplane is a regular plane, in 2D, a line. This idea extends to n dimensions. If points are separable by a hyperplane, they are said to be linearly separable. **Since there are infinite possible separating hyperplanes for any linearly separable feature space, an SVM computes which points are closest to each such hyperplane and uses them to construct a _support vector_. The SVM picks the hyperplane which maximizes the distance - _margin_ - to each support vector.** In this way, we maximize the separating ability of the chosen hyperplane.\n",
        "\n",
        "The core of SVMs is the kernel. We could map all new points from our input space, where they were not separable by a hyperplane, to a higher dimension in which we have found a hyperplane to separate the points in that space. However, that would be extremely computationally expensive for data that needs to be mapped to much higher dimensions. Instead, we **compute the hyperplane in the higher dimension on our training data and map the hyperplane back to the lower-dimension input space to use for classifying our data. This is the _kernel trick_, whereby the kernel (function) enables us to compute distances to new points in the input space without transforming each to the higher dimensional space - drastically reducing the computational complexity of the SVM.**\n",
        "\n",
        " <img src=\"https://github.com/IAT-ExploringAI-2024/Week3-Machine_Learning/blob/main/images/kernel1.png?raw=true\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-VTE6HjL9hf"
      },
      "source": [
        "A linear kernel should always be tested because **a linear kernel is much faster to train than a non-linear kernel**; however, properly tuned, a non-linear kernel often provides the best possible predictive performance. **RBF (radial basis function) is a good default to use for a non-linear kernel** and often is the best non-linear kernel because it usually provides a higher accuracy compared to other non-linear kernels at the cost of higher computational complexity. We can afford to try the RBF kernel because our dataset is small.\n",
        "\n",
        "If you want to explore further please have a look at [this article](https://www.analyticsvidhya.com/blog/2021/10/support-vector-machinessvm-a-complete-guide-for-beginners/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "ruBbt50ML9hf",
        "outputId": "603ee8cd-c16b-4b24-b6f7-fa4482955da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC Model's accuracy on training set is 99.74%\n",
            "SVC Model's accuracy on test set is 54.51%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "model = SVC(\n",
        "    C=10,  #higher the value tighter the margin\n",
        "    gamma='auto',\n",
        "    kernel='rbf',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "print(f'SVC Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'SVC Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
        "\n",
        "# model.fit(X_train_scaled, y_train)\n",
        "# print(f'SVC Model\\'s accuracy on standard scaled training set is {100*model.score(X_train_scaled, y_train):.2f}%')\n",
        "# print(f'SVC Model\\'s accuracy on standard scaled test set is {100*model.score(X_test_scaled, y_test):.2f}%\\n')\n",
        "\n",
        "# model.fit(X_train_minmax, y_train)\n",
        "# print(f'SVC Model\\'s accuracy on minmax scaled training set is {100*model.score(X_train_minmax, y_train):.2f}%')\n",
        "# print(f'SVC Model\\'s accuracy on minmax scaled test set is {100*model.score(X_test_minmax, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIm1a-tiL9hg"
      },
      "source": [
        "Not bad at all for the relatively simple SVC model. **Hyperparameter ð¶ regulates the margin.** It might do well to optimize the SVC model further if we don't find a better one. As it stands, we are looking for considerably higher performance in this task.\n",
        "\n",
        "Check out [this link](https://towardsdatascience.com/visualizing-the-effect-of-hyperparameters-on-support-vector-machines-b9eef6f7357b) for visual representation of affect of changes in C and gamma."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j72LJRfCL9hg"
      },
      "source": [
        "### k Nearest Neighbours\n",
        "\n",
        "k Nearest Neighbours (kNN) is next in line, a tried-and-true machine learning method from the 70s. kNN makes a lot of intuitive sense: imagine plotting points on a graph and drawing gates around points that look like they belong to the same group. That's what it is - we **plot our training samples' features and compare a test sample's features' distance to all those points; then just take the _k_ closest points to the test sample and pick the most frequent label/class.** That's it.\n",
        "\n",
        "kNN is a great starting point for multiclass problems with small datasets, although on large dadtasets less reliable and extremely memory hungry (it stores all training sample points). kNN is also useful in that it makes **no assumptions about the underlying distribution of the data set - so kNNs work well for both linear and non-linear data.** In the 2D example:\n",
        "\n",
        "<img src=\"https://github.com/IAT-ExploringAI-2024/Week3-ClassicML/blob/main/images/knn.png?raw=true\" width=400 height=400 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "qaeCneMiL9hg",
        "outputId": "c37365e2-503a-4e2f-ce89-5b501b1523af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Default kNN Model's accuracy on training set is 64.47%\n",
            "Default kNN Model's accuracy on test set is 51.39%\n",
            "\n",
            "kNN Model's accuracy on training set is 99.65%\n",
            "kNN Model's accuracy on test set is 54.51%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "####### Default kNN  ########\n",
        "model = KNeighborsClassifier(\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'\\n\\nDefault kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Default kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
        "\n",
        "##### (hastily) tuned kNN ######\n",
        "model = KNeighborsClassifier(\n",
        "    n_neighbors = 5,\n",
        "    weights = 'distance',\n",
        "    algorithm = 'brute',\n",
        "    n_jobs=4\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'kNN Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'kNN Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxVEKUyiL9hh"
      },
      "source": [
        "**The brute-force algorithm computes distances between all pairs of points in the training set; works especially well for small datasets** but wildly inefficient w.r.t. increasing samples and feature space dimension. Not bad for 2 minutes of work, but still not suitable for this task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvQ3av4cL9hh"
      },
      "source": [
        "### Random Forests\n",
        "Finally, and before resorting to deep learning methods, let's try a Random Forest -  a model from the 21st century (2001). **We train many distinct decision trees which are essentially directed acyclic graphs (DAGs), somewhat similar to a flow chart. The collection of (decision) trees makes up our Random Forest.**\n",
        "\n",
        "At each node of the tree we have a function (a rule) that evaluates whether the features of samples input to that node belong to one class or another. Each branch of the tree (or, edge of the graph) defines one of two possible results from a node, and each leaf is one of two decisions made by its parent node. **Each tree in the forest evaluates a random subset of the training samples' features and has a rule at each level of the tree that classifies based on these random features - hence, _Random_ Forest. This random selection of features makes Random Forests robust to outliers**, as such features will have less of an impact in the scope of the entire forest, most of whose trees operate on the \"real\" features.\n",
        "\n",
        "**Random Forests are excellent models to use as a benchmark due to their low time complexity to train and because it is an ensemble method, their robustness to unknown distributions and outliers in the dataset,** meaning Random Forests require relatively little exploratory analysis in both the data and training the model to get an idea of their performance in a task.\n",
        "\n",
        "<img src=\"https://github.com/IliaZenkov/sklearn-audio-classification/blob/master/img/randomforest.png?raw=true\" width=500 height=500 />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "j9BWmcV9L9hh",
        "outputId": "56ade201-64bd-459a-d371-97e1753b52ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default Random Forest Model's accuracy on training set is 100.00%\n",
            "Default Random Forest Model's accuracy on test set is 56.25%\n",
            "\n",
            "Random Forest Model's accuracy on training set is 100.00%\n",
            "Random Forest Model's accuracy on test set is 59.72%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "####### Default Random Forest ########\n",
        "model = RandomForestClassifier(\n",
        "    random_state=69\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'Default Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Default Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%\\n')\n",
        "\n",
        "\n",
        "########## Tuned Random Forest #######\n",
        "model = RandomForestClassifier(\n",
        "    n_estimators = 500,\n",
        "    criterion ='entropy',\n",
        "    warm_start = True,\n",
        "    max_features = 'sqrt',\n",
        "    oob_score = True, # more on this below\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(f'Random Forest Model\\'s accuracy on training set is {100*model.score(X_train, y_train):.2f}%')\n",
        "print(f'Random Forest Model\\'s accuracy on test set is {100*model.score(X_test, y_test):.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM9-k8KLL9hi"
      },
      "source": [
        "Not bad for zero effort put into the default model. **Random Forests make a good benchmark model**, especially when strapped for time.\n",
        "\n",
        "**_Max features_ defines size of random feature subset decided upon at each node; sqrt(#features) is a good default for classification.**\n",
        "\n",
        "**_Gini_ and _Entropy_ are functions computing quality of classified samples within each node; they almost always provide similar performance but Entropy is more suited to classification while Gini is better for continuous variables.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnhnxuGXL9hi"
      },
      "source": [
        "\n",
        "As wonderful as Random Forests are, it's clear that we're going to need to pull out bigger guns if we want to get appreciable performance on this dataset, perhaps even with good generalizability on test data. DNNs(Deep Neural Networks) are the next step-up in complexity from classical machine learning models, and we will start at the first rung on that ladder:Simple Perceptron in next lab!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "PyCharm (Speech Classifier)",
      "language": "python",
      "name": "pycharm-6a34225"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}